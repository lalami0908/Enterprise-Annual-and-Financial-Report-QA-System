{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfminer in d:\\lalami\\anaconda\\lib\\site-packages (20191125)\n",
      "Requirement already satisfied: pycryptodome in d:\\lalami\\anaconda\\lib\\site-packages (from pdfminer) (3.9.8)\n"
     ]
    }
   ],
   "source": [
    "! pip install pdfminer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open('./annul_reports/2017_2330_20180605F04_20200708_220143.pdf','rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.pdfinterp import PDFPageInterpreter,PDFResourceManager\n",
    "from pdfminer.converter import TextConverter,PDFPageAggregator\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfdevice import PDFDevice\n",
    "from pdfminer.pdfpage import PDFPage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 47.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# pdf 轉 txt\n",
    "# 获取pdf文档\n",
    "\n",
    "# 创建一个与文档相关的解释器\n",
    "parser = PDFParser(fp)\n",
    "\n",
    "# pdf文档的对象，与解释器连接起来\n",
    "doc = PDFDocument(parser=parser)\n",
    "parser.set_document(doc=doc)\n",
    "\n",
    "# 如果是加密pdf，则输入密码\n",
    "# doc._initialize_password()\n",
    "\n",
    "# 创建pdf资源管理器\n",
    "resource = PDFResourceManager()\n",
    "\n",
    "# 参数分析器\n",
    "laparam=LAParams()\n",
    "\n",
    "# 创建一个聚合器\n",
    "device = PDFPageAggregator(resource,laparams=laparam)\n",
    "\n",
    "# 创建pdf页面解释器\n",
    "interpreter = PDFPageInterpreter(resource,device)\n",
    "\n",
    "# 获取页面的集合\n",
    "counter = 1\n",
    "for page in PDFPage.get_pages(fp):\n",
    "    # 使用页面解释器来读取\n",
    "    interpreter.process_page(page)\n",
    "    \n",
    "    # 使用聚合器来获取内容\n",
    "    layout = device.get_result()\n",
    "    \n",
    "    for out in layout:\n",
    "        if hasattr(out,'get_text'):\n",
    "            #print(out.get_text())\n",
    "            counter += 1\n",
    "            \n",
    "            # 写入txt文件\n",
    "            fw = open('pdfToTxt_part.txt','a',encoding=\"utf-8\")\n",
    "            fw.write(out.get_text())\n",
    "            fw.close()\n",
    "    if counter % 30 == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = open('pdfToTxt_part.txt', 'r', encoding='utf-8')  \n",
    "lines = rf.readlines()\n",
    "fw = open('pdfToTxt_part_paragraph.txt','w',encoding=\"utf-8\")\n",
    "\n",
    "lowLen = 13\n",
    "paragraphLen = 20\n",
    "long_line = \"\"\n",
    "isLong = False\n",
    "\n",
    "\n",
    "for line in lines:  \n",
    "    if len(line) < paragraphLen:\n",
    "        if isLong:\n",
    "            # line = line.replace('\\n', '').replace('\\r', '')\n",
    "            long_line += line\n",
    "            fw.write(long_line)\n",
    "            # print(\"writeLong\", len(long_line),long_line )\n",
    "          \n",
    "            long_line = \"\"\n",
    "            isLong = False\n",
    "        else:\n",
    "            if lowLen < len(line):\n",
    "                 # print(\"writeShort\",len(line),line)\n",
    "                fw.write(line)  \n",
    "    else:\n",
    "        # print(\"isLong\")\n",
    "        line = line.replace('\\n', '').replace('\\r', '')\n",
    "        long_line += line\n",
    "        isLong = True\n",
    "        \n",
    "rf.close()\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gensim\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = open('pdfToTxt_part_paragraph.txt', 'r', encoding='utf-8')  \n",
    "wf = open('pdfToTxt_part_paragraph_cut.txt', 'w', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = rf.readlines()\n",
    "for line in lines:\n",
    "    # print(line)\n",
    "    document = line.replace('<p>', '').replace('</p>', '').replace('\\n', '').replace('，', '').replace('。',\n",
    "                                                                                                          '').replace(\n",
    "        '：', '').replace('？', '').replace(' ', '').replace('\"summarization\":', '').replace('\"article\"', '').replace('{', '').replace('}', '').replace(':', '').replace('<Paragraph>', '')\n",
    "    document_cut = jieba.cut(document, cut_all=False)\n",
    "    result = ' '.join(document_cut)\n",
    "    wf.write(result+'\\n')\n",
    "rf.close()\n",
    "wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "682\n"
     ]
    }
   ],
   "source": [
    "rf = open('pdfToTxt_part_paragraph.txt', 'r', encoding='utf-8') \n",
    "lines = rf.readlines()\n",
    "document = {}\n",
    "count = 0\n",
    "for line in lines:\n",
    "    document[count] = line\n",
    "    count += 1\n",
    "rf.close()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "682\n"
     ]
    }
   ],
   "source": [
    "sentences = gensim.models.doc2vec.TaggedLineDocument('pdfToTxt_part_paragraph.txt')  #  训练\n",
    "model = gensim.models.Doc2Vec(sentences, vector_size=256, window=2)\n",
    "model.train(sentences, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "model.save('part_model.txt')\n",
    "print(len(model.docvecs))  #  所有文章的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "682\n"
     ]
    }
   ],
   "source": [
    "sentences2 = gensim.models.doc2vec.TaggedLineDocument('pdfToTxt_part_paragraph_cut.txt')  #  训练\n",
    "model2 = gensim.models.Doc2Vec(sentences, vector_size=256, window=2)\n",
    "model2.train(sentences, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "model2.save('part_model_02.txt')\n",
    "print(len(model2.docvecs))  #  所有文章的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['公司', '研發', '方向'], ['我', '想', '知道', '公司', '未來', '展望'], ['公司', '最近', '的', '股價'], ['我', '想', '知道', '公司', '今年', '的', '財政狀況'], ['銷售'], ['財務', '分析']]\n"
     ]
    }
   ],
   "source": [
    "temps = [\"公司研發方向\",\n",
    "         \"我想知道公司未來展望\",\n",
    "         \"公司最近的股價\",\n",
    "         \"我想知道公司今年的財政狀況\",\n",
    "         \"銷售\",\n",
    "         \"財務分析\"]\n",
    "\n",
    "query = []\n",
    "for temp in temps:\n",
    "\n",
    "    temp_ = jieba.cut(temp, cut_all=False)\n",
    "    result = ' '.join(temp_)\n",
    "    array = []\n",
    "    get = \"\"\n",
    "    for i in result:\n",
    "        if i == ' ':\n",
    "            array.append(get)\n",
    "            get = \"\"\n",
    "        else:\n",
    "            get+= i\n",
    "    array.append(get)\n",
    "   # print(array)\n",
    "    query.append(array)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['公司', '研發', '方向']\n",
      "[(520, 0.20921361446380615), (149, 0.15752699971199036), (427, 0.1541743129491806)]\n",
      "\n",
      "（一） 公司是否評估往來對象之誠信紀錄，並於其與往來交易對象簽訂之契約中明訂誠信行為條款？\n",
      "\n",
      "--------------------------\n",
      "\n",
      "●  解決新製程開發時的可靠性問題，改善並管理量產時的品質，提供客戶品質問題的解決方案，並提供先進材料與故障分析等服務，以確保公司產品品質及可靠性016\n",
      "\n",
      "--------------------------\n",
      "\n",
      "●  審閱會計師績效評量問卷結果\n",
      "\n",
      "--------------------------\n",
      "['我', '想', '知道', '公司', '未來', '展望']\n",
      "[(168, 0.1844683587551117), (593, 0.17439189553260803), (639, 0.17156219482421875)]\n",
      "\n",
      "前中華民國法務部法律事務司司長\n",
      "\n",
      "--------------------------\n",
      "\n",
      "28,050,000,000\n",
      "\n",
      "--------------------------\n",
      "\n",
      "5,341,120,243\n",
      "\n",
      "--------------------------\n",
      "['公司', '最近', '的', '股價']\n",
      "[(132, 0.16414913535118103), (360, 0.1632072627544403), (289, 0.15698181092739105)]\n",
      "\n",
      "4.  進一步拓展台積公司在新興市場及發展中市場的業務與服務。\n",
      "\n",
      "--------------------------\n",
      "\n",
      "ˇ ˇ ˇ ˇ ˇ ˇ ˇ\n",
      "\n",
      "--------------------------\n",
      "\n",
      "美國喬治亞理工學院材料工程博士\n",
      "\n",
      "--------------------------\n",
      "['我', '想', '知道', '公司', '今年', '的', '財政狀況']\n",
      "[(194, 0.1856417953968048), (559, 0.17419381439685822), (416, 0.17355115711688995)]\n",
      "\n",
      "前G3 Good Governance Group資深顧問（倫敦）倫敦皇家工程學院院士\n",
      "\n",
      "--------------------------\n",
      "\n",
      "3.8.2 本公司與財務資訊透明有關人員，取得主管機關指定之相關證照情形證照\n",
      "\n",
      "--------------------------\n",
      "\n",
      "●  審閱內部稽核報告（閉門會議）\n",
      "\n",
      "--------------------------\n",
      "['銷售']\n",
      "[(78, 0.19075259566307068), (113, 0.1750139594078064), (86, 0.16427697241306305)]\n",
      "\n",
      "民國一百零六年十月，本人以過去三十年來擔任台積公司董事長的身分，宣布將在民國一百零七年六月上旬股東大會之後退休。所有現任董事除了本人之外，均全數同意被提名，且若是當選將續任下屆董事。他們並同意支持台積公司採取雙首長平行領導制度，由劉德音博士擔任董事長，魏哲家博士擔任總裁。這二位目前擔任台積公司總經理暨共同執行長。\n",
      "\n",
      "--------------------------\n",
      "\n",
      "這些都需要低耗電及高效能的中央處理器、繪圖處理器、續擴大市佔率，整合元件製造商委外製造的比例逐漸增硬碟控制器及特殊應用積體電路，並將驅使電腦產業朝加，以及系統公司增加特殊應用元件委外製造等因素，自向更豐富的半導體內容與更先進製程技術邁進。民國一百零六年至民國一百一十一年，積體電路製造服務領域的成長可望較整體半導體產業（不含記憶體）的4%年複合成長率更為強勁。\n",
      "\n",
      "--------------------------\n",
      "\n",
      "●  5奈米鰭式場效電晶體製程技術（5nm  FinFET）開發順利，並預計於民國一百零八年第一季開始試產。相較於7奈米FinFET技術，5奈米FinFET技術速度增快超過15%，或者功耗降低約30%。此外，5奈米FinFET技術自規劃開始，便同時針對行動運算應用與高效能運算元件提供優化的製程選項。\n",
      "\n",
      "--------------------------\n",
      "['財務', '分析']\n",
      "[(207, 0.18514463305473328), (265, 0.1764061450958252), (76, 0.16909459233283997)]\n",
      "\n",
      "- 美國普渡大學電機工程學士及碩士\n",
      "\n",
      "--------------------------\n",
      "\n",
      "台積公司營運組織二廠資深協理\n",
      "\n",
      "--------------------------\n",
      "\n",
      "民國107年晶圓銷售量預期11-12百萬片約當十二吋晶圓未來展望\n",
      "\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in query:\n",
    "    print(i)\n",
    "    sims = model.docvecs.most_similar([model.infer_vector(i)],topn=3)  #输出和训练集中第一个文章最相近的文章\n",
    "    # print(document[i])\n",
    "    print(sims)\n",
    "    for docid, sim in sims:\n",
    "        print()\n",
    "        print(document[docid])\n",
    "        print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['公司', '研發', '方向']\n",
      "[(520, 0.20926041901111603), (149, 0.1555422842502594), (427, 0.15235382318496704)]\n",
      "\n",
      "（一） 公司是否評估往來對象之誠信紀錄，並於其與往來交易對象簽訂之契約中明訂誠信行為條款？\n",
      "\n",
      "--------------------------\n",
      "\n",
      "●  解決新製程開發時的可靠性問題，改善並管理量產時的品質，提供客戶品質問題的解決方案，並提供先進材料與故障分析等服務，以確保公司產品品質及可靠性016\n",
      "\n",
      "--------------------------\n",
      "\n",
      "●  審閱會計師績效評量問卷結果\n",
      "\n",
      "--------------------------\n",
      "['我', '想', '知道', '公司', '未來', '展望']\n",
      "[(168, 0.18446923792362213), (593, 0.1743934005498886), (639, 0.17156080901622772)]\n",
      "\n",
      "前中華民國法務部法律事務司司長\n",
      "\n",
      "--------------------------\n",
      "\n",
      "28,050,000,000\n",
      "\n",
      "--------------------------\n",
      "\n",
      "5,341,120,243\n",
      "\n",
      "--------------------------\n",
      "['公司', '最近', '的', '股價']\n",
      "[(132, 0.16422012448310852), (360, 0.16342902183532715), (289, 0.15714791417121887)]\n",
      "\n",
      "4.  進一步拓展台積公司在新興市場及發展中市場的業務與服務。\n",
      "\n",
      "--------------------------\n",
      "\n",
      "ˇ ˇ ˇ ˇ ˇ ˇ ˇ\n",
      "\n",
      "--------------------------\n",
      "\n",
      "美國喬治亞理工學院材料工程博士\n",
      "\n",
      "--------------------------\n",
      "['我', '想', '知道', '公司', '今年', '的', '財政狀況']\n",
      "[(194, 0.18600010871887207), (559, 0.17423534393310547), (416, 0.17332270741462708)]\n",
      "\n",
      "前G3 Good Governance Group資深顧問（倫敦）倫敦皇家工程學院院士\n",
      "\n",
      "--------------------------\n",
      "\n",
      "3.8.2 本公司與財務資訊透明有關人員，取得主管機關指定之相關證照情形證照\n",
      "\n",
      "--------------------------\n",
      "\n",
      "●  審閱內部稽核報告（閉門會議）\n",
      "\n",
      "--------------------------\n",
      "['銷售']\n",
      "[(78, 0.19075259566307068), (113, 0.1750139594078064), (86, 0.16427697241306305)]\n",
      "\n",
      "民國一百零六年十月，本人以過去三十年來擔任台積公司董事長的身分，宣布將在民國一百零七年六月上旬股東大會之後退休。所有現任董事除了本人之外，均全數同意被提名，且若是當選將續任下屆董事。他們並同意支持台積公司採取雙首長平行領導制度，由劉德音博士擔任董事長，魏哲家博士擔任總裁。這二位目前擔任台積公司總經理暨共同執行長。\n",
      "\n",
      "--------------------------\n",
      "\n",
      "這些都需要低耗電及高效能的中央處理器、繪圖處理器、續擴大市佔率，整合元件製造商委外製造的比例逐漸增硬碟控制器及特殊應用積體電路，並將驅使電腦產業朝加，以及系統公司增加特殊應用元件委外製造等因素，自向更豐富的半導體內容與更先進製程技術邁進。民國一百零六年至民國一百一十一年，積體電路製造服務領域的成長可望較整體半導體產業（不含記憶體）的4%年複合成長率更為強勁。\n",
      "\n",
      "--------------------------\n",
      "\n",
      "●  5奈米鰭式場效電晶體製程技術（5nm  FinFET）開發順利，並預計於民國一百零八年第一季開始試產。相較於7奈米FinFET技術，5奈米FinFET技術速度增快超過15%，或者功耗降低約30%。此外，5奈米FinFET技術自規劃開始，便同時針對行動運算應用與高效能運算元件提供優化的製程選項。\n",
      "\n",
      "--------------------------\n",
      "['財務', '分析']\n",
      "[(207, 0.18514463305473328), (265, 0.1764061450958252), (76, 0.16909459233283997)]\n",
      "\n",
      "- 美國普渡大學電機工程學士及碩士\n",
      "\n",
      "--------------------------\n",
      "\n",
      "台積公司營運組織二廠資深協理\n",
      "\n",
      "--------------------------\n",
      "\n",
      "民國107年晶圓銷售量預期11-12百萬片約當十二吋晶圓未來展望\n",
      "\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in query:\n",
    "    print(i)\n",
    "    sims = model2.docvecs.most_similar([model.infer_vector(i)],topn=3)  #输出和训练集中第一个文章最相近的文章\n",
    "    # print(document[i])\n",
    "    print(sims)\n",
    "    for docid, sim in sims:\n",
    "        print()\n",
    "        print(document[docid])\n",
    "        print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
